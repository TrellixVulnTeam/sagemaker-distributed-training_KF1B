{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker와 병렬로 SageMaker 분산 모델을 사용하여 모델 병렬화로 훈련 작업 시작\n",
    "\n",
    "SageMaker 분산 모델 병렬 (SageMaker Distributed Model Parallel, SMP)은 GPU 메모리 제한으로 인해 이전에 학습하기 어려웠던 대규모 딥러닝 모델을 훈련하기 위한 모델 병렬 처리 라이브러리입니다. SageMaker Distributed Model Parallel은 여러 GPU 및 인스턴스에서 모델을 자동으로 효율적으로 분할하고 모델 훈련을 조정하므로 더 많은 매개 변수로 더 큰 모델을 생성하여 예측 정확도를 높일 수 있습니다.\n",
    "\n",
    "이 노트북을 사용하여 TensorFlow 및 [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#train-a-model-with-the-sagemaker-python-sdk)를 사용하여 모델을 훈련하도록 Sagemaker Distributed Model Parallel을 구성합니다.\n",
    "\n",
    "### 추가 리소스\n",
    "\n",
    "Amazon SageMaker를 처음 사용하는 경우, SageMaker가 Docker를 사용하여 사용자 지정 모델을 훈련하는 방법을 이해하는 데 다음 정보들이 도움이 될 수 있습니다.\n",
    "\n",
    "* 자체 훈련 이미지와 함께 Amazon SageMaker를 사용하는 방법에 대한 자세한 내용은 [Use Your Own Training Algorithms\n",
    "](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)을 참조하세요.\n",
    "\n",
    "* Docker를 사용하여 Amazon SageMaker로 자체 모델을 훈련하는 방법에 대한 자세한 내용은 [Example Notebooks: Use Your Own Algorithm or Model](https://docs.aws.amazon.com/sagemaker/latest/dg/adv-bring-own-examples.html)을 참조하세요.\n",
    "\n",
    "* Amazon SageMaker 및 Tensorflow를 사용한 분산 훈련의 다른 예제를 보려면 [Distributed TensorFlow training using Amazon SageMaker\n",
    "](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/distributed_tensorflow_mask_rcnn)\n",
    "을 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker 초기화\n",
    "\n",
    "다음 셀을 실행하여 노트북 인스턴스를 초기화합니다. 이 노트북을 실행하는 데 사용되는 SageMaker 실행 역할을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = get_execution_role() # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f'SageMaker Execution Role:{role}')\n",
    "\n",
    "session = boto3.session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 스크립트 준비\n",
    "\n",
    "다음 코드 셀을 실행하여 TensorFlow 버전 2.3에 대한 예제 훈련 스크립트를 확인합니다. `tf2.py`는 순수 모델 병렬화이고 `tf2_hvd.py`는 Horovod를 사용한 데이터/모델 병렬화입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of a training scripts that you can use to configure -\n",
    "# SageMaker Distributed Model Parallel with TensorFlow versions 2.3\n",
    "!cat utils/tf2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of a training scripts that you can use to configure -\n",
    "# SageMaker Distributed Model Parallel using Horvod with TensorFlow 2.3\n",
    "!cat utils/tf2_hvd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker 훈련 작업 정의\n",
    "\n",
    "다음으로 SageMaker Estimator API를 사용하여 SageMaker 훈련 작업을 정의합니다. [`PyTorchEstimator`](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)를 사용하여 Amazon SageMaker가 훈련에 사용하는 EC2 인스턴스의 수와 유형을 정의합니다. 인스턴스에 연결된 볼륨의 크기도 포함됩니다.\n",
    "\n",
    "Estimator 호출 시, 아래의 인자값들을 업데이트해야 합니다.\n",
    "* `processes_per_host`\n",
    "* `entry_point`\n",
    "* `instance_count`\n",
    "* `instance_type`\n",
    "* `base_job_name`\n",
    "\n",
    "또한, SageMaker Distributed Model Parallel 라이브러리에 대한 설정 파라메터들을 제공하고 수정할 수 있습니다. 이러한 파라메터들은 아래와 같이 `distributions` 인수를 통해 전달됩니다.\n",
    "\n",
    "### 사용할 EC2 인스턴스의 유형 및 개수 업데이트\n",
    "\n",
    "예시 스크립트인 `tf2.py`, `tf2_hvd.py` 중 하나에서 `entry_point`를 선택합니다.\n",
    "\n",
    "`processes_per_host`를 지정하고 `tf2.py`의 경우 2개만 사용하고 `tf2_hvd.py`의 경우 4개 이상을 사용해야 합니다. 파티션의 배수여야 하며 기본값은 2입니다.\n",
    "\n",
    "`instance_type` 및 `instance_count` 에서 지정하는 인스턴스 유형과 인스턴스 수에 따라 Amazon SageMaker가 훈련 중에 사용하는 GPU 수가 결정됩니다. 명시적으로`instance_type`은 단일 인스턴스의 GPU 수를 결정하고 그 숫자에 `instance_count`를 곱합니다.\n",
    "\n",
    "`instance_type`및 `instance_count` 값을 지정하여 학습에 사용할 수있는 총 GPU 수가 Estimator API에 있는 모델 병렬 분포 인수의 `parameters`에 있는 `partitions`와 같도록 해야 합니다.\n",
    "\n",
    "`tf2_hvd.py`를 사용하는 경우, 훈련 작업에서 지원할 수 있는 총 모델 복제본 수는 지정한 총 GPU 수를 `partitions`으로 나눈 값과 같습니다. 따라서 데이터 병렬화에 Horovod를 사용하는 경우 총 GPU 수를 원하는 모델 복제본 수에 `partitions`를 곱한 값(`total-model-replicas` x `partitions`)으로 지정하셔야 합니다.\n",
    "\n",
    "인스턴스 유형을 조회하려면 [Amazon EC2 인스턴스 유형](https://aws.amazon.com/sagemaker/pricing/)을 참조하세요.\n",
    "\n",
    "### 훈련 중 체크 포인트 업로드 또는 이전 훈련에서 체크 포인트 재개\n",
    "또한 사용자가 훈련 중에 체크 포인트를 업로드하거나, 이전 훈련에서 체크 포인트를 재개할 수 있는 맞춤형 방법을 제공합니다. 이러한 방법들을 `tf2.py` 예제 스크립트에 통합하혔으며, `aws_s3_sync`,`sync_local_checkpoints_to_s3` 및 `sync_s3_checkpoints_to_local` 함수를 참조하시면 됩니다. 이 예제에서는 `sync_local_checkpoints_to_s3`을 사용하여 훈련 중에 체크 포인트만 업로드합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`entry_point`, `instance_count`, `instance_type` 및 `base_job_name`을 업데이트한 후 다음을 실행하여 estimator를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "mpioptions = \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "mpioptions += \"--mca btl_vader_single_copy_mechanism none \"\n",
    "\n",
    "#choose an experiment name (only need to create it once)\n",
    "experiment_name = \"SM-MP-DEMO\"\n",
    "\n",
    "all_experiment_names = [exp.experiment_name for exp in Experiment.list()]\n",
    "# Load the experiment if it exists, otherwise create \n",
    "if experiment_name not in all_experiment_names:\n",
    "    customer_churn_experiment = Experiment.create(\n",
    "        experiment_name=experiment_name, sagemaker_boto_client=boto3.client(\"sagemaker\")\n",
    "    )\n",
    "else:\n",
    "    customer_churn_experiment = Experiment.load(\n",
    "        experiment_name=experiment_name, sagemaker_boto_client=boto3.client(\"sagemaker\")\n",
    "    )\n",
    "\n",
    "# Create a trial for the current run\n",
    "trial = Trial.create(\n",
    "        trial_name=\"SMD-MP-demo-{}\".format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())),\n",
    "        experiment_name=customer_churn_experiment.experiment_name,\n",
    "        sagemaker_boto_client=boto3.client(\"sagemaker\"),\n",
    "    )\n",
    "\n",
    "\n",
    "smd_mp_estimator = TensorFlow(\n",
    "          entry_point=\"tf2.py\", # Pick your train script\n",
    "          source_dir=\"utils\",\n",
    "          role=role,\n",
    "          framework_version='2.3.1',\n",
    "          py_version='py37',\n",
    "          instance_type='ml.p3.16xlarge',\n",
    "          sagemaker_session=sagemaker_session,\n",
    "          instance_count=1,\n",
    "          distribution={\n",
    "              \"smdistributed\": {\n",
    "                  \"modelparallel\": {\n",
    "                      \"enabled\":True,\n",
    "                      \"parameters\": {\n",
    "                          \"microbatches\": 2, \n",
    "                          \"partitions\": 2, \n",
    "                          \"pipeline\": \"interleaved\", \n",
    "                          \"optimize\": \"memory\",\n",
    "                          #\"horovod\": True, #Set to True if using the horovod script\n",
    "                      }\n",
    "                  }\n",
    "              },\n",
    "              \"mpi\": {\n",
    "                    \"enabled\": True,\n",
    "                    \"processes_per_host\": 2, # Pick your processes_per_host\n",
    "                    \"custom_mpi_options\": mpioptions \n",
    "              },\n",
    "          },\n",
    "          base_job_name=\"SMD-MP-demo\"\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 estimator를 사용하여 SageMaker 훈련 작업을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_mp_estimator.fit(\n",
    "        experiment_config={\n",
    "            \"ExperimentName\": customer_churn_experiment.experiment_name,\n",
    "            \"TrialName\": trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": \"Training\",\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
