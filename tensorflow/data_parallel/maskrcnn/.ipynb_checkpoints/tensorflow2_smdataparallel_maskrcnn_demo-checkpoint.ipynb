{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 및 SMDataParallel을 사용한 분산 데이터 병렬 MaskRCNN 훈련\n",
    "\n",
    "SMDataParallel은 Amazon SageMaker의 새로운 기능으로 딥러닝 모델을 더 빠르고 저렴하게 훈련할 수 있습니다. SMDataParallel은 PyTorch, TensorFlow 및 MXNet을 위한 분산 데이터 병렬 훈련 프레임워크입니다.\n",
    "\n",
    "이 노트북 예제는 [Amazon SageMaker](https://aws.amazon.com/sagemaker/)에서 TensorFlow(버전 2.3.1)와 함께 SMDataParallel을 사용하여 [Amazon FSx for Lustre file-system](https://aws.amazon.com/fsx/lustre/) 파일 시스템을 데이터 소스로 사용하는 MaskRCNN 모델 훈련 방법을 보여줍니다. \n",
    "\n",
    "본 예제의 개요는 다음과 같습니다.\n",
    "\n",
    "1. [Amazon S3](https://aws.amazon.com/s3/)에서 COCO 2017 데이터셋을 준비합니다.\n",
    "2. Amazon FSx Luster 파일 시스템을 생성하고 S3에서 파일 시스템으로 데이터를 가져옵니다.\n",
    "3. Docker 훈련 이미지를 빌드하고 [Amazon ECR](https://aws.amazon.com/ecr/)에 푸시합니다.\n",
    "4. SageMaker에 대한 데이터 입력 채널을 구성합니다.\n",
    "5. 하이퍼 파라메터를 세팅합니다.\n",
    "6. 훈련 지표를 정의합니다.\n",
    "7. 훈련 작업을 정의하고 분산 전략을 SMDataParallel로 설정하고 훈련을 시작합니다.\n",
    "\n",
    "**참고:** 대규모 훈련 데이터셋의 경우 SageMaker 훈련 작업을 위한 입력 파일 시스템으로 (Amazon FSx)[https://aws.amazon.com/fsx/] 를 사용하는 것이 좋습니다. SageMaker에 대한 FSx 파일 입력은 SageMaker 훈련 작업을 시작할 때마다 훈련 데이터 다운로드를 방지하고 (SageMaker 훈련 작업에 대한 S3 입력으로 수행됨) 우수한 데이터 읽기 처리량(throughput)을 제공하므로 SageMaker에서 훈련 시작 시간을 크게 단축합니다.\n",
    "\n",
    "**참고:** 이 예제는 SageMaker Python SDK v2.X가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker 초기화\n",
    "\n",
    "노트북 인스턴스를 초기화합니다. aws 리전, sagemaker 실행 역할을 가져옵니다.\n",
    "\n",
    "IAM 역할 arn은 데이터에 대한 훈련 및 호스팅 액세스 권한을 부여하는 데 사용됩니다. 이를 생성하는 방법은 [Amazon SageMaker 역할](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html)을 참조하세요. 노트북 인스턴스, 훈련 및 호스팅에 둘 이상의 역할이 필요한 경우 `sagemaker.get_execution_role()`을 적절한 전체 IAM 역할 arn 문자열로 변경해 주세요. 위에서 설명한 대로 FSx를 사용할 것이므로, 이 IAM 역할에 `FSx Access` 권한을 연결해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! python3 -m pip install --upgrade sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = get_execution_role() # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f'SageMaker Execution Role:{role}')\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "print(f'AWS account:{account}')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(f'AWS region:{region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker 훈련 이미지 준비\n",
    "\n",
    "1. SageMaker는 기본적으로 최신 [Amazon Deep Learning Container Images (DLC)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md) PyTorch 훈련 이미지를 사용합니다. 이 단계에서는 이를 기본 이미지로 사용하고 MaskRCNN 모델 훈련에 필요한 추가 종속성 패키지들을 설치합니다.\n",
    "2. Github 저장소 https://github.com/HerringForks/DeepLearningExamples.git 에서 PyTorch-SMDataParallel BERT 훈련 스크립트를 사용할 수 있도록 만들었습니다. 이 저장소는 모델 훈련을 실행하기 위해 훈련 이미지에서 복제됩니다.\n",
    "\n",
    "### Docker 이미지 빌드 및 ECR로 푸시\n",
    "\n",
    "아래 명령을 실행하여 도커 이미지를 빌드하고 ECR에 푸시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"<IMAGE_NAME>\"  # Example: tf2-mask-rcnn-smdataparallel-sagemaker\n",
    "tag = \"<IMAGE_TAG>\"   # Example: latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize ./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "! chmod +x build_and_push.sh; bash build_and_push.sh {region} {image} {tag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker용 FSx 입력 데이터 준비\n",
    "\n",
    "1. S3에서 훈련 데이터셋을 다운로드하고 준비합니다.\n",
    "2. 여기에 나열된 단계에 따라 훈련 데이터(https://docs.aws.amazon.com/fsx/latest/LustreGuide/create-fs-linked-data-repo.html)가 있는 S3 버켓과 연결된 FSx를 생성합니다. S3 액세스를 허용하는 엔드포인트를 VPC에 추가해야 합니다.\n",
    "3. 여기에 나열된 단계에 따라 FSx(https://aws.amazon.com/blogs/machine-learning/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/)를 사용하도록 SageMaker 훈련 작업을 구성합니다. \n",
    "\n",
    "\n",
    "### 중요 사항\n",
    "\n",
    "1. SageMaker 노트북 인스턴스를 시작할 때 FSx에서 사용하는 것과 동일한 `서브넷(subnet)` 과`vpc` 및 `보안 그룹(security group)`을 사용해야 합니다. SageMaker 훈련 작업에서 동일한 구성이 사용됩니다.\n",
    "2. '보안 그룹'에서 적절한 인바운드/출력 규칙을 설정했는지 확인합니다. 특히 SageMaker가 훈련 작업에서 FSx 파일 시스템에 액세스하려면 이러한 포트를 열어야합니다. https://docs.aws.amazon.com/fsx/latest/LustreGuide/limit-access-security-groups.html\n",
    "3. 이 SageMaker 훈련 작업을 시작하는 데 사용된 `SageMaker IAM 역할`이 `AmazonFSx`에 액세스할 수 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker TensorFlow Estimator function options\n",
    "\n",
    "다음 코드 블록에서 다른 인스턴스 유형, 인스턴스 수 및 분산 전략을 사용하도록 estimator 함수를 업데이트할 수 있습니다. 이전 코드 셀에서 검토한 훈련 스크립트도 estimator 함수로 전달합니다.\n",
    "\n",
    "**인스턴스 유형**\n",
    "\n",
    "SMDataParallel은 아래 인스턴스 유형들만 SageMaker 상에서의 모델 훈련을 지원합니다.\n",
    "1. ml.p3.16xlarge\n",
    "1. ml.p3dn.24xlarge [권장]\n",
    "1. ml.p4d.24xlarge [권장]\n",
    "\n",
    "**인스턴스 수**\n",
    "\n",
    "최상의 성능과 SMDataParallel을 최대한 활용하려면 2개 이상의 인스턴스를 사용해야 하지만, 이 예제를 테스트하는 데 1개를 사용할 수도 있습니다.\n",
    "\n",
    "**배포 전략**\n",
    "\n",
    "DDP 모드를 사용하려면 `distribution` 전략을 업데이트하고 `smdistributed dataparallel`을 사용하도록 설정해야 합니다.\n",
    "\n",
    "### 훈련 스크립트\n",
    "\n",
    "Github 저장소( https://github.com/HerringForks/deep-learning-models.git)에서 레퍼런스 TensorFlow-SMDataParallel BERT 훈련 스크립트를 사용할 수 있도록 만들었습니다. 저장소를 복제하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone herring (smdataparallel) forks repository for reference implementation of H\n",
    "!rm -rf DeepLearningExamples\n",
    "!git clone --recursive https://github.com/HerringForks/DeepLearningExamples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.p3dn.24xlarge\" # Other supported instance type: ml.p3.16xlarge\n",
    "instance_count = 2 # You can use 2, 4, 8 etc.\n",
    "docker_image = f\"{account}.dkr.ecr.{region}.amazonaws.com/{image}:{tag}\" # YOUR_ECR_IMAGE_BUILT_WITH_ABOVE_DOCKER_FILE\n",
    "username = 'AWS'\n",
    "subnets = ['<SUBNET_ID>'] # Should be same as Subnet used for FSx. Example: subnet-0f9XXXX\n",
    "security_group_ids = ['<SECURITY_GROUP_ID>'] # Should be same as Security group used for FSx. sg-03ZZZZZZ\n",
    "job_name = 'tf2-smdataparallel-mrcnn-fsx' # This job name is used as prefix to the sagemaker training job. Makes it easy for your look for your training job in SageMaker Training job console.\n",
    "file_system_id='<FSX_ID>' # FSx file system ID with your training dataset. Example: 'fs-0bYYYYYY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM_DATA_ROOT = '/opt/ml/input/data/train'\n",
    "\n",
    "hyperparameters={\n",
    "    \"mode\": \"train\",\n",
    "    \"checkpoint\": '/'.join([SM_DATA_ROOT, 'model/resnet/resnet-nhwc-2018-02-07/model.ckpt-112603']), \n",
    "    \"eval_samples\": 5000,\n",
    "    \"init_learning_rate\": 0.04, \n",
    "    \"learning_rate_steps\": \"3750,5000\", \n",
    "    \"model_dir\": \"/opt/ml/code/checkpoints/tensorflow_mask_rcnn\", \n",
    "    \"num_steps_per_eval\": 462,\n",
    "    \"total_steps\": 500,\n",
    "    \"train_batch_size\": 4,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"training_file_pattern\": '/'.join([SM_DATA_ROOT, 'train']), \n",
    "    \"validation_file_pattern\": '/'.join([SM_DATA_ROOT, 'val']), \n",
    "    \"val_json_file\": '/'.join([SM_DATA_ROOT, 'annotations/instances_val2017.json']),    \n",
    "    \"amp\": '',\n",
    "    \"use_batched_nms\": '',\n",
    "    \"xla\": '',\n",
    "    \"nouse_custom_box_proposals_op\": '',\n",
    "    \"seed\": 987\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='DeepLearningExamples/TensorFlow2/Segmentation/MaskRCNN/mask_rcnn_sm.py',\n",
    "                        role=role,\n",
    "                        image_uri=docker_image,\n",
    "                        source_dir='.',\n",
    "                        framework_version='2.3.1',\n",
    "                        py_version='py3',\n",
    "                        instance_count=instance_count,\n",
    "                        instance_type=instance_type,\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        subnets=subnets,\n",
    "                        hyperparameters=hyperparameters,\n",
    "                        security_group_ids=security_group_ids,\n",
    "                        debugger_hook_config=False,\n",
    "                        # Training using SMDataParallel Distributed Training Framework\n",
    "                        distribution={'smdistributed':{\n",
    "                                            'dataparallel':{\n",
    "                                                    'enabled': True\n",
    "                                                 }\n",
    "                                          }\n",
    "                                      }\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "file_system_directory_path='YOUR_MOUNT_PATH_FOR_TRAINING_DATA' # NOTE: '/fsx/' will be the root mount path. Example: '/fsx/mask_rcnn/PyTorch'\n",
    "file_system_access_mode='rw'\n",
    "file_system_type='FSxLustre'\n",
    "train_fs = FileSystemInput(file_system_id=file_system_id,\n",
    "                                    file_system_type=file_system_type,\n",
    "                                    directory_path=file_system_directory_path,\n",
    "                                    file_system_access_mode=file_system_access_mode)\n",
    "data_channels = {'train': train_fs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit SageMaker training job\n",
    "estimator.fit(inputs=data_channels, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 리소스\n",
    "\n",
    "Amazon SageMaker를 처음 사용하는 경우, SageMaker가 Docker를 사용하여 사용자 지정 모델을 훈련하는 방법을 이해하는 데 다음 정보들이 도움이 될 수 있습니다.\n",
    "\n",
    "* 자체 훈련 이미지와 함께 Amazon SageMaker를 사용하는 방법에 대한 자세한 내용은 [Use Your Own Training Algorithms\n",
    "](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)을 참조하세요.\n",
    "\n",
    "* Docker를 사용하여 Amazon SageMaker로 자체 모델을 훈련하는 방법에 대한 자세한 내용은 [Example Notebooks: Use Your Own Algorithm or Model](https://docs.aws.amazon.com/sagemaker/latest/dg/adv-bring-own-examples.html)을 참조하세요.\n",
    "\n",
    "* Amazon SageMaker 및 Tensorflow를 사용한 분산 훈련의 다른 예제를 보려면 [Distributed TensorFlow training using Amazon SageMaker\n",
    "](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/advanced_functionality/distributed_tensorflow_mask_rcnn)\n",
    "을 참조하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
